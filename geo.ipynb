{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load your data (replace this with your actual data loading code)\n",
    "    df_Kenya = pd.read_csv('Kenya_training.csv')\n",
    "    df_Spain = pd.read_csv('Spain_training.csv')\n",
    "    df_VNM = pd.read_csv('VNM_training.csv')\n",
    "    \n",
    "    # Assuming 'TARGET' is the name of your target column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    X_Kenya = df_Kenya.drop(['TARGET','ID'], axis=1)\n",
    "    y_Kenya = df_Kenya['TARGET']\n",
    "    \n",
    "    \n",
    "    X_Spain = df_Spain.drop(['TARGET','ID'], axis=1)\n",
    "    y_Spain = df_Spain['TARGET']\n",
    "    \n",
    "    \n",
    "    X_VNM = df_VNM.drop(['TARGET','ID'], axis=1)\n",
    "    y_VNM = df_VNM['TARGET']\n",
    "    \n",
    "    label_encoder = LabelEncoder()\n",
    "    y_Kenya = label_encoder.fit_transform(y_Kenya)\n",
    "    y_Spain = label_encoder.fit_transform(y_Spain)\n",
    "    y_VNM = label_encoder.fit_transform(y_VNM)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VegetationIndexTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, nir_col='nir_p50', red_col='red_p50', blue_col='blue_p50'):\n",
    "        self.nir_col = nir_col\n",
    "        self.red_col = red_col\n",
    "        self.blue_col = blue_col\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        for col in [self.nir_col, self.red_col, self.blue_col]:\n",
    "            X[col] = X[col] * 0.0001\n",
    "        \n",
    "        X['NDVI'] = (X[self.nir_col] - X[self.red_col]) / (X[self.nir_col] + X[self.red_col])\n",
    "        X['EVI'] = 2.5 * ((X[self.nir_col] - X[self.red_col]) / \n",
    "                     (X[self.nir_col] + 6 * X[self.red_col] - 7.5 * X[self.blue_col] + 1))\n",
    "        L = 0.5\n",
    "        X['SAVI'] = ((X[self.nir_col] - X[self.red_col]) / \n",
    "                (X[self.nir_col] + X[self.red_col] + L)) * (1 + L)\n",
    "        \n",
    "        return X\n",
    "\n",
    "def create_vegetation_index_pipeline():\n",
    "    feature_columns = ['ID', 'Lon', 'Lat', 'blue_p50', 'green_p50', 'nir_p50', 'nira_p50', \n",
    "                       're1_p50', 're2_p50', 're3_p50', 'red_p50', 'swir1_p50', 'swir2_p50', \n",
    "                       'VV_p50', 'VH_p50']\n",
    "    \n",
    "    vegetation_pipeline = Pipeline([\n",
    "        ('veg_indices', VegetationIndexTransformer()),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "    \n",
    "    return vegetation_pipeline\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train_Kenya, X_test_Kenya, y_train_Kenya, y_test_Kenya = train_test_split(X_Kenya, y_Kenya, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_Spain, X_test_Spain, y_train_Spain, y_test_Spain = train_test_split(X_Spain, y_Spain, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_VNM, X_test_VNM, y_train_VNM, y_test_VNM = train_test_split(X_VNM, y_VNM, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the pipeline\n",
    "feature_pipeline = create_vegetation_index_pipeline()\n",
    "\n",
    "\n",
    "\n",
    "# Create a full pipeline including the model\n",
    "full_pipeline = Pipeline([\n",
    "    ('features', feature_pipeline),\n",
    "    ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "\n",
    "# Fit the pipeline on the training data\n",
    "# full_pipeline.fit(X_train_Kenya, y_train_Kenya)\n",
    "full_pipeline.fit(X_train_Spain, y_train_Spain)\n",
    "# full_pipeline.fit(X_train_VNM, y_train_VNM)\n",
    "\n",
    "# Make predictions on the test set\n",
    "# y_pred_Kenya = full_pipeline.predict(X_test_Kenya)\n",
    "y_pred_Spain = full_pipeline.predict(X_test_Spain)\n",
    "# y_pred_VNM = full_pipeline.predict(X_test_VNM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spain Accuracy: 0.9360\n",
      "\n",
      "Classification Report:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "    Agricultural Plastic       0.93      0.92      0.93        75\n",
      "Non-Agricultural Plastic       0.94      0.95      0.94        97\n",
      "\n",
      "                accuracy                           0.94       172\n",
      "               macro avg       0.94      0.93      0.93       172\n",
      "            weighted avg       0.94      0.94      0.94       172\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy score\n",
    "# accuracy_Kenya = accuracy_score(y_test_Kenya, y_pred_Kenya)\n",
    "accuracy_Spain = accuracy_score(y_test_Spain, y_pred_Spain)\n",
    "# accuracy_VNM = accuracy_score(y_test_VNM, y_pred_VNM)\n",
    "\n",
    "# print(f\"Kenya Accuracy: {accuracy_Kenya:.4f}\")\n",
    "print(f\"Spain Accuracy: {accuracy_Spain:.4f}\")\n",
    "# print(f\"VNM Accuracy: {accuracy_VNM:.4f}\")\n",
    "\n",
    "# Generate and print classification report\n",
    "# class_report_Kenya = classification_report(y_test_Kenya, y_pred_Kenya, target_names=['Agricultural Plastic', 'Non-Agricultural Plastic'])\n",
    "# print(\"\\nClassification Report:\")\n",
    "# print(class_report_Kenya)\n",
    "\n",
    "class_report_Spain = classification_report(y_test_Spain, y_pred_Spain, target_names=['Agricultural Plastic', 'Non-Agricultural Plastic'])\n",
    "print(\"\\nClassification Report:\")\n",
    "print(class_report_Spain)\n",
    "\n",
    "# class_report_VNM = classification_report(y_test_VNM, y_pred_VNM, target_names=['Agricultural Plastic', 'Non-Agricultural Plastic'])\n",
    "# print(\"\\nClassification Report:\")\n",
    "# print(class_report_VNM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def add_id_column(df, file_name):\n",
    "  \"\"\"Adds an ID column based on the file name and index.\"\"\"\n",
    "  file_prefix = file_name.split('_')[0]\n",
    "  df['ID'] = df.index.map(lambda x: f\"{file_prefix}_{x+1}\")\n",
    "  return df\n",
    "\n",
    "t1 = pd.read_csv('Kenya_testing.csv')\n",
    "t2 = pd.read_csv('Spain_validation.csv')\n",
    "t3 = pd.read_csv('VNM_testing.csv')\n",
    "\n",
    "\n",
    "test1 = add_id_column(t1, 'Kenya')  \n",
    "test2 = add_id_column(t2, 'Spain')\n",
    "test3 = add_id_column(t3, 'VNM')\n",
    "\n",
    "t1 = pd.DataFrame(test1)\n",
    "t2 = pd.DataFrame(test2)\n",
    "t3 = pd.DataFrame(test3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sample_submission = pd.read_csv('SampleSubmission.csv')\n",
    "print(sample_submission.head())\n",
    "test = pd.concat([t1, t2, t3], ignore_index=True, join='outer')\n",
    "Test = pd.DataFrame(test)\n",
    "\n",
    "merged_data = pd.merge(sample_submission, Test, on='ID', how='left')\n",
    "\n",
    "\n",
    "testdata = merged_data.drop(columns=['ID','TARGET'])\n",
    "\n",
    "test_pred = full_pipeline.predict(testdata)\n",
    "\n",
    "# Create submission DataFrame\n",
    "submission_pred = pd.DataFrame({'ID': sample_submission['ID'], 'TARGET': test_pred})\n",
    "\n",
    "# Save to CSV\n",
    "submission_pred.to_csv('pred_submission.csv', index=False)\n",
    "\n",
    "submission_pred.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature names after transformation\n",
    "feature_names = X.columns.tolist() + ['NDVI', 'EVI', 'SAVI']\n",
    "\n",
    "\n",
    "# Print feature importances\n",
    "importances = full_pipeline.named_steps['classifier'].feature_importances_\n",
    "feature_importance = pd.DataFrame({'feature': feature_names, 'importance': importances})\n",
    "feature_importance = feature_importance.sort_values('importance', ascending=False).reset_index(drop=True)\n",
    "print(\"\\nTop 10 Feature Importances:\")\n",
    "print(feature_importance.head(10))\n",
    "\n",
    "\n",
    "\n",
    "# Verify the number of features\n",
    "print(f\"\\nNumber of features: {len(feature_names)}\")\n",
    "print(f\"Number of importance values: {len(importances)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
